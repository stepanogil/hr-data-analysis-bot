from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores.azuresearch import AzureSearch
import os  
from dotenv import load_dotenv

load_dotenv()

# Azure OpenAI embedding model
EMBEDDING_MODEL_NAME  = os.getenv("OPENAI_API_EMBEDDING_MODEL")
EMEBEDDING_MODEL_DEPLOYMENT_NAME = os.getenv("OPENAI_API_EMBEDDING_DEPLOYMENT")
SEARCH_INDEX_NAME = os.getenv("SEARCH_INDEX_NAME")

# retrieval algorithm
RAG_RETRIEVAL_ALGORITHM = os.getenv("RAG_RETRIEVAL_ALGORITHM")

# Azure Cognitive Search vector db
vector_store_address = os.getenv("AZURE_SEARCH_SERVICE_ENDPOINT")  
vector_store_password = os.getenv("AZURE_SEARCH_ADMIN_KEY") 
index_name = SEARCH_INDEX_NAME

# Azure embedding model
embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME,
                                   deployment=EMEBEDDING_MODEL_DEPLOYMENT_NAME)

# initialize vector store
vector_store =  AzureSearch(
    azure_search_endpoint=vector_store_address,
    azure_search_key=vector_store_password,
    index_name=index_name,
    embedding_function=embedding_model.embed_query)

def retrieve_relevant_kb(query):
    """
    Retrieves the top three relevant knowledge base chunks related to a given query from Azure Cognitive Search.

    This function utilizes the Azure Cognitive Search vector store integrated with OpenAI embeddings to perform 
    a similarity search. It takes a user query, embeds it using the specified Azure OpenAI embedding model, and 
    retrieves the most relevant knowledge base chunks based on the specified retrieval algorithm. The function 
    returns the content of the top three matching documents.

    The Azure Cognitive Search vector store is configured with necessary credentials and the embedding model is 
    initialized at the beginning of the script. The function leverages these configurations to perform the search.

    Args:
        query (str): The query string for which relevant knowledge base chunks are to be retrieved.

    Returns:
        dict: A dictionary containing the contents of the top three relevant documents. The keys are 'doc0', 'doc1', 
              and 'doc2', each corresponding to one of the top three documents.
    """
    # NOTE: docstrings generated by ChatGPT
   
    docs = vector_store.similarity_search(
        query=query,
        k=3,
        search_type=RAG_RETRIEVAL_ALGORITHM,
    )
    return {"doc0": docs[0].page_content, "doc1": docs[1].page_content, "doc2": docs[2].page_content}


